---
author: "Copyright: Optimization Team 2022"
date: "Compiled on `r format(Sys.time(), '%B %d, %Y')`"
output: 
  prettydoc::html_pretty:
    theme: "architect"
params:
  data:
    label: "Input file:"
    value: "*.csv"
    input: text
  businessarea:
    label: "Business Area:"
    value: "BCWS"
    input: text
  path:
    label: "Directory being reported on:"
    value: "////////SERVER////SHARE/////ROOT_FOLDER////SUB_FOLDER or Q:////ROOT_FOLDER////SUB_FOLDER"
    input: text
  folder:
    label: "Folder Name:"
    value: "Network_Folder"
    input: text
  san_tier:
    label: "SAN Tier:"
    value: "2"
    input: select
    choices: [1, 2, 3]
  collected:
    label: "date the raw data was collected:"
    value: 2022-05-05
    input: text
title: "Non-SFP Consumption & Cost Report on the `r params$folder` folder for `r params$businessarea`" 
subtitle: "Data collected on `r params$collected`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
library(dbplyr)
library(dplyr)
library(forcats)
library(glue)
library(here)
library(htmltools)
library(knitr)
library(lubridate)
library(openxlsx)
library(scales)
library(stringr)
library(stringi)
library(tidyverse)
library(shiny)
library(zoo)
```

```{r apply team logo, echo=FALSE}
#load image file to be used as header
htmltools::img(src = knitr::image_uri(file.path(here("scripts"), "GFX_OptimizationLogo-Icon_v2.png")), 
               alt = 'logo', 
               style = 'position:bottom:0; left:0; padding:10px;',
               width = "350px",
               heigth = "350px")
```

```{r set system environment, include = FALSE}
# This chunk is helpful if you're using an IDE like VS Code
# You can find the correct directory by typing Sys.getenv("RSTUDIO_PANDOC") into the console
Sys.setenv(RSTUDIO_PANDOC="C:/Program Files/RStudio/bin/pandoc")
```

```{r load data, include = FALSE}
# load the csv file containing relevant network share data
here::here()
raw_data <- read_csv((here("source", glue("{params$data}"))), col_names = TRUE) %>% 
  rename(
    path = DirectoryName,
    filename = Name,
    filetype = Extension,
    creationdate = CreationTime,
    lastaccessed = LastAccessTime,
    lastmodified = LastWriteTime,
    )

names(raw_data) <- tolower(names(raw_data))
```

```{r functions, include = FALSE}
convert.date <- function(.data) {
format(as.POSIXct(.data,format='%m/%d/%Y %H:%M'),format='%Y-%m-%d')
}

sheet.names <- function(.data) {
addWorksheet(excel, .data)
}

dt.worksheets <- function(x, .data) {
writeDataTable(excel, sheet = x, .data, colNames = TRUE, withFilter = TRUE)
}

freeze.panes <- function(x) {
freezePane(excel, x, firstRow = TRUE)
}
```

```{r manipulate dataframe, include = FALSE}
# rename the Length field and convert the value from bytes (b) to gigabytes (GB)
formatted_data <- raw_data %>% 
  mutate(folderdepth = str_count(path, "\\\\")) %>%
  mutate(folderdepth = folderdepth-2) %>%
  mutate(sizegb = length / 1e+9) %>%
  mutate(sizegb = round(sizegb, 3)) %>%
  mutate(backup_cost = sizegb * .36) %>% 
  mutate(obj_store_cost = sizegb * 0.07) %>% 
  mutate(object_storage_cost = round((obj_store_cost), 2))
```

```{r update timestamp, include = FALSE}
formatted_data$creationdate <- convert.date(formatted_data$creationdate)
formatted_data$lastaccessed <- convert.date(formatted_data$lastaccessed) 
formatted_data$lastmodified <- convert.date(formatted_data$lastmodified)
```

```{r calculate SAN costs, include = FALSE}
if (params$san_tier == 1){
  formatted_data$SAN_cost <- formatted_data$sizegb * 1.2
} else if (params$san_tier == 2){
  formatted_data$SAN_cost <- formatted_data$sizegb * 0.9
} else {
  formatted_data$SAN_cost <- formatted_data$sizegb * 0.55
}

formatted_data$monthly_SAN <- round((formatted_data$SAN_cost + formatted_data$backup_cost),2)

formatted_data <- formatted_data %>% 
  select(filename, filetype, path, folderdepth, sizegb, creationdate, lastaccessed, lastmodified, monthly_SAN, obj_store_cost, object_storage_cost) 
```

```{r, include = FALSE}
#count total number of files
count_files <- nrow(formatted_data)
count_files_formatted <- format(count_files, big.mark = ",", scientific = FALSE)
```

```{r, include = FALSE}
# show size and cost breakdown by folders
folder_detail <- formatted_data %>% 
  group_by(path) %>% 
  summarize(FolderSize_GB = sum(sizegb), FolderCost = sum(monthly_SAN), ObjStor_Estimate = sum(object_storage_cost))
head(folder_detail)
```

```{r, include = FALSE}
# count the number of unique folders contained in the path
folder_count <- unique(folder_detail$path)
folder_count <- length(folder_count)
folder_count <- format(folder_count, big.mark = ",", scientific = FALSE)
head(folder_count)
```

```{r, include = FALSE}
# count the number of files in each folder within the path
folder_filetally <- formatted_data %>%
  group_by(path) %>% 
  summarise("FileCount" = n())
head(folder_filetally)
```

```{r, include = FALSE}
# make table
table_pathsize_tallyfiles <- inner_join(folder_detail,folder_filetally, by = "path") 

# find size of entire path being searched
path_size <- sum(table_pathsize_tallyfiles$FolderSize_GB)
path_size <- format(path_size, big.mark = ",", scientific = FALSE) 

head(table_pathsize_tallyfiles)
```

```{r, include = FALSE}
# Count the number of '\'s in each element of string
table_pathsize_tallyfiles$FolderDepth <- str_count(table_pathsize_tallyfiles$path, "\\\\") 

start_depth <- str_count({params$path}, "////")

# Subtract the starting folder depth to get a custom count based on parameters given
table_pathsize_tallyfiles$FolderDepth <- table_pathsize_tallyfiles$FolderDepth - start_depth

# count the folder depth, find max and mean depth
depth_count <- unique(table_pathsize_tallyfiles$FolderDepth)
max_depth <- max(table_pathsize_tallyfiles$FolderDepth)
mean_depth <- as.integer(mean(table_pathsize_tallyfiles$FolderDepth))

# tally and display folders based on folder depth
table_folderdepth_tallyfolders <- table_pathsize_tallyfiles %>%
  group_by(FolderDepth) %>% 
  tally(name = "FolderCount")

table_pathsize_tallyfiles <- table_pathsize_tallyfiles[order(table_pathsize_tallyfiles$FolderDepth),]
```

```{r size of entire share in GB, echo = FALSE}
share_size <- sum(table_pathsize_tallyfiles$FolderSize_GB)
sharesize <- format(share_size, big.mark = ",", scientific = FALSE)
```

```{r, include = FALSE}
# find files that are duplicated in both name and size
duplicate_files <- formatted_data %>% 
  group_by(filename, sizegb) %>% 
  filter( n() > 1 )

duplicate_files_formatted <- duplicate_files %>% 
  select (filename,	path,	sizegb,	lastaccessed,	lastmodified, monthly_SAN) 

duplicate_files_formatted <- duplicate_files_formatted[order(-duplicate_files_formatted$monthly_SAN),]
```

```{r, echo = FALSE}
totalSAN <- sum(formatted_data$monthly_SAN)
total_SAN <- dollar(totalSAN)
objstorecost <- sum(formatted_data$object_storage_cost)
objstore_cost <- dollar(objstorecost)
annualsavings <- sum(totalSAN - objstorecost) * 12
annual_savings <- dollar(annualsavings)
```

```{r, echo = FALSE}
dup_cost <- sum(duplicate_files$monthly_SAN)
dup_cost <- dollar(dup_cost)

dup_cost_half <- (sum(duplicate_files$monthly_SAN)) / 2
dup_cost_half <- dollar(dup_cost_half)
```

```{r, include = FALSE}
# find any empty folders within search parameters
empty_folders <- table_pathsize_tallyfiles %>% 
  filter(FileCount == 0) %>% 
  select(path)

# count number of empty folders
empty_count <- unique(empty_folders$Path)
empty_count <- length(empty_count)
empty_count <- format(empty_count, big.mark = ",", scientific = FALSE) 

if(empty_count <= 0){
empty_count <- "None"
}
```

```{r, include = FALSE}
date <- format(as.POSIXct(params$collected, format = '%Y-%m-%d'))
#date <- as.Date({params$collected}, "%Y-%m-%d") 
dt_less5 <- ymd(date) - years(5)

# files last accessed more than 5 years ago
files_accessed_5plus <- formatted_data %>% 
  filter(lastaccessed < dt_less5) %>% 
  select(filename, path, sizegb, lastaccessed, lastmodified) 

files_accessed_5plus <- files_accessed_5plus[(order(as.Date(files_accessed_5plus$lastaccessdate))),]


# files last modified more than 5 years ago
files_modified_5plus <- formatted_data %>% 
  filter(lastmodified < dt_less5) %>% 
  select(filename, path, sizegb, lastaccessed, lastmodified)

files_modified_5plus <- files_modified_5plus[(order(as.Date(files_modified_5plus$modificationdate))),]
```

```{r, include = FALSE}
la_count <- nrow(files_accessed_5plus)
lm_count <- nrow(files_modified_5plus)

la_5plus_count <- format(la_count, big.mark = ",", scientific = FALSE)
lm_5plus_count  <- format(lm_count, big.mark = ",", scientific = FALSE)

la_percent <- (la_count / count_files) * 100
lm_percent <- (lm_count / count_files) * 100

la_percent <- format(round(la_percent, 1), nsmall = 1)
lm_percent <- format(round(lm_percent, 1), nsmall = 1)
```

```{r, echo = FALSE}
glue('The size of the {params$folder} folder is {sharesize} GB.')

glue('There are {folder_count} folders in {params$folder}. {empty_count} of these folders are empty.')

glue('The maximum folder depth in {params$folder} is {max_depth} and the average is {mean_depth}.')

knitr::kable(table_folderdepth_tallyfolders, caption = params$folder)

glue('{la_percent}% of files were last accessed over 5 years ago ({la_5plus_count} files).')

glue('{lm_percent}% of files were last modified over 5 years ago ({lm_5plus_count} files).')

glue('The monthly cost of the {params$folder} folder is {total_SAN}.')

#glue('If this data were held in Object Storage, the monthly cost would be {objstore_cost}. 
#The annual savings would be {annual_savings}!')

glue('There are files saved in more than one location on the {params$folder} folder that total a monthly cost of {dup_cost}.') 

glue('If the duplicates in {params$folder} were found & removed, at least half this amount ({dup_cost_half}) could be saved!')
```

```{r, include = FALSE}
# create output file names based on parameters
output_excel = paste0("Non-SFP_Custom_Report_", params$folder, "_", params$businessarea, "_", params$collected, ".xlsx")
```

```{r write output to Excel file, include = FALSE}
# create workbook
excel <- createWorkbook(output_excel)

# create sheet names
firstSheet = "Folder Details Overview"
secondSheet = "Duplicate Files"
thirdSheet = "Last Accessed 5+ Years"
fourthSheet = "Last Modified 5+ Years"
fifthSheet = "Empty Folders"

# add worksheets to workbook
sheet.names(firstSheet)
sheet.names(secondSheet)
sheet.names(thirdSheet)
sheet.names(fourthSheet)
sheet.names(fifthSheet)

# assign data tables to worksheets, apply filter across all sheets
dt.worksheets(1,table_pathsize_tallyfiles) 
dt.worksheets(2,duplicate_files_formatted)
dt.worksheets(3,files_accessed_5plus)
dt.worksheets(4,files_modified_5plus)
dt.worksheets(5,empty_folders)

# freeze top row of all sheets
freeze.panes(1)
freeze.panes(2)
freeze.panes(3)
freeze.panes(4)
freeze.panes(5)

# set custom column widths for all sheets
setColWidths(excel, sheet = 1, cols = c(1:6), widths = c(75, 20, 20, 20, 20, 20))
setColWidths(excel, sheet = 2, cols = c(1, 2, 3, 4:7), widths = c(50, 75, 20, 20, 20, 20, 20))
setColWidths(excel, sheet = 3, cols = c(1:6), widths = c(50, 75, 20, 20, 20, 20))
setColWidths(excel, sheet = 4, cols = c(1:6), widths = c(50, 75, 20, 20, 20, 20))
setColWidths(excel, sheet = 5, cols = c(1:5), widths = c(75, 20, 20, 20, 20))

# set currency format on column
sty1 = createStyle(numFmt="$0.00")
addStyle(excel, sheet = 1, sty1, rows=2:(nrow(table_pathsize_tallyfiles)+1), cols=3)
addStyle(excel, sheet = 1, sty1, rows=2:(nrow(table_pathsize_tallyfiles)+1), cols=4)
addStyle(excel, sheet = 2, sty1, rows=2:(nrow(duplicate_files_formatted)+1), cols=6)

# save the workbook to file
saveWorkbook(excel, file = here("output", output_excel), overwrite = TRUE)
```



